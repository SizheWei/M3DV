{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part1: 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Credit: sentdex\n",
    "# # link: https://pythonprogramming.net/3d-convolutional-neural-network-machine-learning-tutorial/\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# data_dir = 'data/demo/nodule/'\n",
    "# patients = os.listdir(data_dir)\n",
    "# labels_df = pd.read_csv('data/demo/train_data.csv',index_col=0)\n",
    "\n",
    "# labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证数据集的大小\n",
    "# for patient in patients[:8]:\n",
    "#     patient_name = patient[0:-4]\n",
    "#     label = labels_df.get_value(patient_name, 'lable')\n",
    "#     path = data_dir + patient\n",
    "#     # a couple great 1-liners from: https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial\n",
    "#     scan = np.load(path)\n",
    "#     print(scan['voxel'],label)\n",
    "#     plt.figure()\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(scan['voxel'][37])\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(scan['seg'][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集存储在muchdata.npy中：\n",
    "# much_data = []\n",
    "# for num, patient in enumerate(patients):\n",
    "#     patient_name = patient[0:-4]\n",
    "#     label = labels_df.get_value(patient_name, 'lable')\n",
    "#     path = data_dir + patient\n",
    "#     img_data = np.load(path)\n",
    "#     voxel = img_data['voxel'].astype(np.int32)\n",
    "# #     plt.imshow(voxel[50])\n",
    "# #     print(label)\n",
    "#     much_data.append([voxel,label])\n",
    "    \n",
    "# np.save('muchdata', much_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## part2: 神经网络模块\n",
    " some codes work below, follow the tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 怎么把数据我现在的数据变成需要的数据？\n",
    "\n",
    "- 先要理清思路，现在的数据长什么样子?\n",
    "source https://blog.csdn.net/DaVinciL/article/details/78793067 介绍了CIFAR数据集\n",
    "- 现在的网络每层的输入输出是什么样子？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv3d(1, 5, kernel_size=(17, 17, 17), stride=(1, 1, 1))\n",
       "  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(5, 10, kernel_size=(17, 17, 17), stride=(1, 1, 1))\n",
       "  (fc1): Linear(in_features=21970, out_features=16000, bias=True)\n",
       "  (fc2): Linear(in_features=16000, out_features=8000, bias=True)\n",
       "  (fc3): Linear(in_features=8000, out_features=2000, bias=True)\n",
       "  (fc4): Linear(in_features=2000, out_features=200, bias=True)\n",
       "  (fc5): Linear(in_features=200, out_features=80, bias=True)\n",
       "  (fc6): Linear(in_features=80, out_features=10, bias=True)\n",
       "  (fc7): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input_channel:1; output_channel(#filter):10; kernel_size: 10*10\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=5, kernel_size=17)\n",
    "        # maxpool: kernel: 2; stride: 2\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        # input_channel:10; output_channel(#filter):20; kernel_size: 10*10\n",
    "        self.conv2 = nn.Conv3d(in_channels=5, out_channels=10, kernel_size=17)\n",
    "        self.fc1 = nn.Linear(10 * 13 * 13 * 13, 16000)\n",
    "        self.fc2 = nn.Linear(16000, 8000)\n",
    "        self.fc3 = nn.Linear(8000, 2000)\n",
    "        self.fc4 = nn.Linear(2000, 200)\n",
    "        self.fc5 = nn.Linear(200, 80)\n",
    "        self.fc6 = nn.Linear(80, 10)\n",
    "        self.fc7 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 10 * 13 * 13 * 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.softmax(self.fc7(x)) # 变成概率形式\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.load to import data, devide dataset into 2 parts: train_data & validation_data:\n",
    "# credit: cheez & Matthew Kerian\n",
    "# link: https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56243777\n",
    "'''use older to successfully load the data:'''\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "data_ineed = np.load('muchdata.npy')\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "\n",
    "# If you are working with the basic sample data, use maybe 2 instead of 100 here... you don't have enough data to really do this\n",
    "train_data = data_ineed[:-60]\n",
    "validation_data = data_ineed[-60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 0.694\n",
      "[1,    40] loss: 0.692\n",
      "[1,    60] loss: 0.691\n",
      "[1,    80] loss: 0.691\n",
      "[1,   100] loss: 0.704\n",
      "[1,   120] loss: 0.700\n",
      "[1,   140] loss: 0.694\n",
      "[1,   160] loss: 0.698\n",
      "[1,   180] loss: 0.700\n",
      "[1,   200] loss: 0.695\n",
      "[1,   220] loss: 0.686\n",
      "[1,   240] loss: 0.703\n",
      "[1,   260] loss: 0.703\n",
      "[1,   280] loss: 0.693\n",
      "[1,   300] loss: 0.691\n",
      "[1,   320] loss: 0.694\n",
      "[1,   340] loss: 0.679\n",
      "[1,   360] loss: 0.690\n",
      "[1,   380] loss: 0.674\n",
      "[1,   400] loss: 0.688\n",
      "[2,    20] loss: 0.706\n",
      "[2,    40] loss: 0.714\n",
      "[2,    60] loss: 0.714\n",
      "[2,    80] loss: 0.697\n",
      "[2,   100] loss: 0.692\n",
      "[2,   120] loss: 0.689\n",
      "[2,   140] loss: 0.670\n",
      "[2,   160] loss: 0.701\n",
      "[2,   180] loss: 0.708\n",
      "[2,   200] loss: 0.697\n",
      "[2,   220] loss: 0.678\n",
      "[2,   240] loss: 0.711\n",
      "[2,   260] loss: 0.710\n",
      "[2,   280] loss: 0.689\n",
      "[2,   300] loss: 0.690\n",
      "[2,   320] loss: 0.695\n",
      "[2,   340] loss: 0.672\n",
      "[2,   360] loss: 0.690\n",
      "[2,   380] loss: 0.670\n",
      "[2,   400] loss: 0.689\n",
      "[3,    20] loss: 0.709\n",
      "[3,    40] loss: 0.719\n",
      "[3,    60] loss: 0.699\n",
      "[3,    80] loss: 0.697\n",
      "[3,   100] loss: 0.691\n",
      "[3,   120] loss: 0.688\n",
      "[3,   140] loss: 0.669\n",
      "[3,   160] loss: 0.701\n",
      "[3,   180] loss: 0.708\n",
      "[3,   200] loss: 0.697\n",
      "[3,   220] loss: 0.678\n",
      "[3,   240] loss: 0.712\n",
      "[3,   260] loss: 0.710\n",
      "[3,   280] loss: 0.689\n",
      "[3,   300] loss: 0.689\n",
      "[3,   320] loss: 0.695\n",
      "[3,   340] loss: 0.672\n",
      "[3,   360] loss: 0.690\n",
      "[3,   380] loss: 0.670\n",
      "[3,   400] loss: 0.689\n",
      "[4,    20] loss: 0.709\n",
      "[4,    40] loss: 0.719\n",
      "[4,    60] loss: 0.699\n",
      "[4,    80] loss: 0.697\n",
      "[4,   100] loss: 0.691\n",
      "[4,   120] loss: 0.688\n",
      "[4,   140] loss: 0.669\n",
      "[4,   160] loss: 0.701\n",
      "[4,   180] loss: 0.708\n",
      "[4,   200] loss: 0.697\n",
      "[4,   220] loss: 0.677\n",
      "[4,   240] loss: 0.712\n",
      "[4,   260] loss: 0.710\n",
      "[4,   280] loss: 0.688\n",
      "[4,   300] loss: 0.689\n",
      "[4,   320] loss: 0.695\n",
      "[4,   340] loss: 0.672\n",
      "[4,   360] loss: 0.690\n",
      "[4,   380] loss: 0.670\n",
      "[4,   400] loss: 0.689\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_data, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs: tensor(100*(100*100)), label\n",
    "        inputs_numpy, labels = data\n",
    "        inputs = torch.from_numpy(inputs_numpy)\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        inputs = inputs.float()\n",
    "        inputs = inputs.cuda()\n",
    "        labels = torch.from_numpy(np.asarray(labels)).float()\n",
    "        labels = labels.long() #credit: ptrblck; link: https://discuss.pytorch.org/t/runtimeerror-expected-object-of-scalar-type-long-but-got-scalar-type-float-when-using-crossentropyloss/30542/4\n",
    "        labels = labels.unsqueeze(0)\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        outputs = torch.log(outputs) # 为了放进损失函数 NLLLoss() 中：\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv3d(1, 5, kernel_size=(17, 17, 17), stride=(1, 1, 1))\n",
       "  (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv3d(5, 10, kernel_size=(17, 17, 17), stride=(1, 1, 1))\n",
       "  (fc1): Linear(in_features=21970, out_features=16000, bias=True)\n",
       "  (fc2): Linear(in_features=16000, out_features=8000, bias=True)\n",
       "  (fc3): Linear(in_features=8000, out_features=2000, bias=True)\n",
       "  (fc4): Linear(in_features=2000, out_features=200, bias=True)\n",
       "  (fc5): Linear(in_features=200, out_features=80, bias=True)\n",
       "  (fc6): Linear(in_features=80, out_features=10, bias=True)\n",
       "  (fc7): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivi/anaconda3/envs/3dunet/lib/python3.7/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "predict_value = []\n",
    "true_value = []\n",
    "for i, data in enumerate(validation_data, 0):\n",
    "    inputs_numpy, labels = data\n",
    "    inputs = torch.from_numpy(inputs_numpy)\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    inputs = inputs.unsqueeze(0)\n",
    "    inputs = inputs.float()\n",
    "    inputs = inputs.cuda()\n",
    "    labels = torch.from_numpy(np.asarray(labels)).float()\n",
    "    labels = labels.long() #credit: ptrblck; link: https://discuss.pytorch.org/t/runtimeerror-expected-object-of-scalar-type-long-but-got-scalar-type-float-when-using-crossentropyloss/30542/4\n",
    "    labels = labels.unsqueeze(0)\n",
    "    labels = labels.cuda()\n",
    "\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    outputs = outputs.cpu()\n",
    "    outputs = outputs.squeeze(0)\n",
    "    outputs = outputs.detach().numpy()\n",
    "    predict_value.append(outputs[1])\n",
    "    \n",
    "    labels = labels.cpu()\n",
    "    labels = labels.detach().numpy()\n",
    "    labels[0]\n",
    "    true_value.append(labels[0])\n",
    "    \n",
    "    # ROC-AUC reference: https://www.cnblogs.com/dlml/p/4403482.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(true_value, predict_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
